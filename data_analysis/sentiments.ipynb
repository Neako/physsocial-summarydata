{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy as sp\n",
    "\n",
    "import glob\n",
    "import os,sys,inspect\n",
    "import argparse\n",
    "import re\n",
    "import ast\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from xml.etree import ElementTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CURRENTDIR = os.path.dirname(os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe()))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading textblob extracted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_xml(file_path):\n",
    "    \"\"\"Read XML file and return list of tokens\n",
    "    \n",
    "    Known structure:\n",
    "    ---------\n",
    "    <?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
    "    <sentiment language=\"fr\" version=\"1.1\" author=\"Tom De Smedt, Walter Daelemans, fabelier.org\" license=\"PDDL\">\n",
    "        ... List of tokens:\n",
    "        <word form=\"abandonné\" pos=\"JJ\" polarity=\"-0.30\" subjectivity=\"0.40\" intensity=\"1.0\" confidence=\"0.9\" />\n",
    "        \n",
    "    </sentiment>\n",
    "    \n",
    "    Input:\n",
    "    ---------\n",
    "    file_path: str\n",
    "        local path, Jupyter cannot access files outside of root, XML file\n",
    "    \n",
    "    Output:\n",
    "    ---------\n",
    "    tree: xml.etree.ElementTree.Element\n",
    "    \"\"\"\n",
    "    tree = ElementTree.parse(file_path)\n",
    "    # getroot() gets document, getchildren()[0] gets sample ==> access tokens\n",
    "    return tree.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_document = read_xml(os.path.join(CURRENTDIR,'data/fr-sentiment.xml'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_to_pandas(document):\n",
    "    \"\"\"Select words & tags from xml \n",
    "    \n",
    "    Input:\n",
    "    -------\n",
    "    document: xml.etree.ElementTree.Element\n",
    "\n",
    "    Output:\n",
    "    -------\n",
    "    sentence: dataframe\n",
    "        shape ['form', 'polarity', 'subjectivity', 'intensity', 'confidence']\n",
    "    \"\"\"\n",
    "    vocab = []\n",
    "    for child in document:\n",
    "        if child.tag == 'word':\n",
    "            # first child is solution, if exists\n",
    "            vocab.append({'form': child.attrib['form'],\n",
    "                    'polarity': child.attrib['polarity'], 'subjectivity': child.attrib['subjectivity'], \n",
    "                    'intensity': child.attrib['intensity'], 'confidence': child.attrib['confidence']\n",
    "                    })\n",
    "    return pd.DataFrame(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "          form polarity subjectivity intensity confidence\n0    abandonné    -0.30         0.40       1.0        0.9\n1   abandonnée    -0.30         0.40       1.0        0.8\n2  abandonnées    -0.30         0.40       1.0        0.8\n3   abandonnés    -0.30         0.40       1.0        0.8\n4    abasourdi     0.24         0.55       1.0        0.7",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>form</th>\n      <th>polarity</th>\n      <th>subjectivity</th>\n      <th>intensity</th>\n      <th>confidence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>abandonné</td>\n      <td>-0.30</td>\n      <td>0.40</td>\n      <td>1.0</td>\n      <td>0.9</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>abandonnée</td>\n      <td>-0.30</td>\n      <td>0.40</td>\n      <td>1.0</td>\n      <td>0.8</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>abandonnées</td>\n      <td>-0.30</td>\n      <td>0.40</td>\n      <td>1.0</td>\n      <td>0.8</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>abandonnés</td>\n      <td>-0.30</td>\n      <td>0.40</td>\n      <td>1.0</td>\n      <td>0.8</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>abasourdi</td>\n      <td>0.24</td>\n      <td>0.55</td>\n      <td>1.0</td>\n      <td>0.7</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "pd_vocab = sentiment_to_pandas(ref_document)\n",
    "pd_vocab.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After loading the textblob data inside a dataframe, we load the vocabulary used during the sessions and fuse both dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_excel(os.path.join(CURRENTDIR,\"data/extracted_data.xlsx\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "\"ah ouais c'est un masque de Batman je sais pas moi j'ai pas vu grand chose d'autre elle était bien belle par contre c'est elle était brillante elle c'était c'était un donc ouais. donc concernant l'image il s'agissait d'une d'une aubergine on aurait dit qu'elle était taillée comme si y avait un masque de Batman et là ah oui oui oui oui elle était elle était propre elle était non ça elle était taillée elle était pas oxydée elle était crue que là quand c'est en aubergine. ah d'accord ok ouais donc on on on a vu exactement la même chose donc là t'as un masque de tortue ninja tout à l'heure c'était Batman hein ouais mais c'est bizarre parce que le le citron enfin le lime le citron vert comme ça enfin je sais pas toi mais moi c'est pas quelque chose que je mange c'est plutôt pour les cocktails que pour que que pour faire une ratatouille quoi donc je sais pas alimentation ouais fruits et légumes c'est aussi une sorte d'. ok donc là il s'agissait d'un demi citron vert avec un masque de tortue \""
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "sentences = '. '.join(results.extract_text.values)\n",
    "sentences[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spacy POS analysis & word comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp=sp.load('fr_core_news_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_nlp = nlp(sentences.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vocab_sentence(loaded_nlp):\n",
    "    \"\"\"From a nlp applied to a set of sentences, extract lemmas and pos tags for each token; return unique items\n",
    "    \"\"\"\n",
    "    vocab = []\n",
    "    for d in loaded_nlp:\n",
    "        vocab.append((d.lemma_, d.pos_))\n",
    "    return sorted(list(set(vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "2803\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[('&', 'CCONJ'),\n (\"'\", 'PUNCT'),\n ('-', 'PUNCT'),\n ('-fin', 'PUNCT'),\n ('-lors', 'ADV'),\n ('.', 'PUNCT'),\n ('1', 'NUM'),\n ('10', 'NUM'),\n ('2000', 'NUM'),\n ('3', 'NUM'),\n ('4', 'NUM'),\n ('5', 'NUM'),\n ('8000', 'NUM'),\n ('90', 'NUM'),\n ('?', 'PUNCT'),\n ('a.', 'AUX'),\n ('a.', 'VERB'),\n ('abandonner', 'NOUN'),\n ('abandonner', 'VERB'),\n ('abiment', 'VERB')]"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "used_vocab = vocab_sentence(loaded_nlp)\n",
    "print(len(used_vocab))\n",
    "used_vocab[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: some punctuation and split words as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(281, 5)"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "# extracting lemmas only\n",
    "u_vocab = [x for x,_ in used_vocab]\n",
    "# selecting common vocab between spacy and textblob\n",
    "sel_vocab = pd_vocab[pd_vocab.form.isin(u_vocab)]\n",
    "sel_vocab.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "1658"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "# vocab in text but not listed in textblob:\n",
    "rem_vocab = sorted(list(set(u_vocab) - set(pd_vocab[pd_vocab.form.isin(u_vocab)].form.values)))\n",
    "len(rem_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_vocab.to_excel('polarized_vocab.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "& ' - -fin -lors . 1 10 2000 3 4 5 8000 90 ? a. abandonner abiment abimer abimé abimée abimées abimés abord abricot abîmer accent accord accrobaties accrocher accueil accueillir achat acheter acide adhérer admiration ados adresser adulte affaiblir affaisser afficher afrique agacer agir agriculteur agriculture agrume ah aider ailleurs aimble aimer air alcoolique aliment alimentaire alimentation aller allo allonger allure allusion alors ambiguité ambivalent amener amibe amocher amour amuser améliorer amérique an analyser ananas angle angoisser animation animer anne annoncer année ant antagoniste anti anti-pub antioxydant antithèse antman apelle apparaître apparemment apparence appel appeler appetissante appetissants applatie apple apport apporter approcher apprécier appétissant appêtissant appêtissante après araignée arbre argent argument arnaquer arriver arriérer arrondir arrêter arôme aseptisé asiatique aspect assaisonnement assez association associer attacher attaquer attendre attention attirer attitude attractif attraction attraper attrayant attribut au au-dessus aucun aujourd'huie auquel aurélie aussi autant auteur automatique autour autrichien aux auxquels avaler avancer avant avatar avec avengers aventurer aviné avis avocat avoir avouer bac bactérie bagarrer bah balancer ballant banane bandana bandeau bander bandit banga bar baraque barbu barquette barrer baser batailler bateau batman baton battre bayer bazar be bec beh beigbeder ben besoin beurrer bien-être bio biologique birgit bière blaguer blaser bloc bodybuilding boire boisson bonbon bonjour bord bosser boucher bouffer bouger bougie bouillir boulot bourreau bourrer boursoufflée bousculer boxer boxeur brancher bras brider brillanter briller brin brouillard bruire brunir brut c'est-à-diree ca cabosser cabrioler cacher cafétéria cagoule cagoulé cagoulée caisse calibrer calin cambodge camion campagne campagner caméra canard cantine capacité cape car cargo caricaturer carnard carnaval carotter carrer carries carrément cartable cas cascader casquer casser catherine catégorie causer ce ceci celer celui celui-ci celui-là censurer cerise cerisier certes cerveau cete chacun chair chaleur champ chance changement changer chapeau chaque chef chemin chercher cheveu chez chiffrer chimique chiner choc chocolat choisir choix choquer chose chuchoter chuter ci ciblage cibler cicatrice cifre cinq cinéma citron citrouille classement classer classifier clean clicher clore club clé cocard cocktail cogner cohérence cohérent coin coller colorer colère combattre combattres comestible comic comics comme commencer comment commentaire commercer communication comnbat comnbattre comparaison comparer compassion complexer complexité compliquer compléter comprendre compter compétition concerner concilier conclusion concorder condamnation confiance confirmer confiture congénaires connait connaître consensus conservateur conserver considérer consistance conso consommateur consommation consommer consonance constraste container contenir contenter conter contexte continuer continuité contrairement contrarier contraster contredire contrer cool cools copyright corps correspondre corrélation costumer coucou couleur coup couper coupure courber courir couronner couteau coïncidence cramer creuser crin critiquer croire croquant croquer crédibilité crédible créer cueillir cuisiner cultiver culture côté d dan danser dark dc de deadpool debout dedans deformée dehors delà demander demi-citron dentiste depuis derrière des-z-héros descendre design dessert dessin dessiner dessous dessus destination destiner destroy deux devenir deviner devoir difformer différemment différence différencier différer dire direction diriger discrimination discréditer discussion discusssion discuter disney disperser disproportionner distancer do docker domestiquer donald donatello donc donner dont douleur douter drait du duck durer dès déborder début décalage décaler déchet décomposer décorer découpage découper décrire défaut défendre défenseur défi défoncer déformer défraichie dégoulinant dégouliner dégout dégoutant dégoutée dégrader dégueu dégueuler déguisement déguiser déjeuner déjà délaisser délirer délà démoraliser dénoncer départir dépasser dépendre dépenser dépiter déplacement dépressif déprimer déranger dériver désespérer désoler détail déterminer détester détour détournement développer dééjà eau effectivement effet effevtivement effrayer eh elina embaucher embêter empathique empoisonner empreint empêcher en en-dessous encore endroit enfant enfiler enfin engager enjouer enlever enrober ensemble ensuite entendre entièrement entrejambe entrer entretenir envahir envers envier environnement envoyer esprit espèce espérer essayer esthétique et etats etcetera euhh euhu euro europe eux-mêmes eventé exactement exagérer exceller exception exclusivement excuser exemple exister expert explication expliquer exporter exposer expressif expression exprimer expérience extrêmement fabriquer face facilement faciès faillir faim faire fait falloir familiariaser familiariser famille fanta farfelu fatiguer favoriser façon femme fente fermentation fermer feuiller fiable fiction figurer fil filer fille film finalement financer finir flaque flasque flotter flouer focaliser foi fonction fondre forcer forcément formatées former foulard foutre fracasser frai fraiche fraiser framboise france franchement frapper frigo frimer frire frite froncer fruit fruitier fuhrat fun funky furhat fêter gachis gager gagner gamin gangster garder gars garçon gaspillage gaspiller geler genou genre gens gentillesse glacer glamour glisser globalement globuleux go gonfler gosse gourmandise gouvernement goût goûter grain graine grandir grands-parents graphisme graver griffer grimacer grimper grogner groseille grossir grossissement grouper guerre gueuler guillemet guise gâcher gâchis gène gélatineux génération gêner ha habiller habit habiter habitude habituer halloween hamburger handicaper harcèlement haribo hasard hausser healthy hein heure hey hier histoire hochet homme honnêtement hop hormone houpette hulk humaniser humour hyper hypothèse hé héros hésiter ia ici identifier idole idée il illumination illustrer image imager imagination imaginer immeuble impartir imperfection impertinence impliquer implorer importance importation importer impression impressionner inaperçu incitation inciter indication indice indéchiffrable indéfinissable infiltrer info information ingrédient inhabituel insecticide insiprait insister inspirer instantanément instinctivement intelligence intentionné interaction interdire intergénérationnel interner interroger interrompre intrus intuitif intégrer intéresser intérêt inverser irm ironman irradier issu jack jamais jambe japon jardin jeter jevais joie joker jouer jouet jour journée julie jurer justement justicier justifier juteux kart kevin kilométrer kiwi l'- label laisser laitier lancer lasser lassitude lavage laver le lendemain lequel leur lever libèrerait libérer lien lier lieu limer limiter lire lisser liste littéralement live logiquement logo loin longtemps lors loucher louper ludique lui lui-même luire lumière lunette lustrer lutter là là-bas là-dessus lèpre légume m m'as mac machin mai main maintenir maintien maison maladie malbouffe malformée malqué maltraitance maltraiter man manga mangeable manger mangue manière manquer marathon marcher mariner mario marketing marquant marquer marrer martyriser marvel maskass masquer masser matin mec membre mer merder mesquin message mesurer mettre mettres mh mi-temps micro microbe midi mieux milieu millionaire miner mineur ministère minot minuter miser miss mode modéliser moins mois moisir moitié mojitos moment mon monder mondialisation monsanto monsato monter montrer morceau morganer morphologie mot motif motiver mouais moulant mouvement mr mur muscler mythe mythique méchanceté mécher méfiance mélanger mémoire môme mûrir n'- naruto ne neiger ni nickel ninja ninjas niquel niveau noailles noeud nom normalement notamment notre nourriture noël nuancer nuire nutritif nécessairement négatif négative négliger oasis objectif objet obliger observer obtenir occasion océan oeil offensif ogm oh ok olive ombrer on opposer opposition optique or orangina ordinateur ordre ordure oreille organisme oser ou ouah ouais oublier ouh oula ouvrir oxyder où paint pan panier panneau papaye paquet par paradoxal paraître parc parce parcourir pardon parent parer parfaire parfois parfum parler parodier partir partout pas passe-partout passer patate pattern paumer pause paut payer pays peai peau peiner peler pendre penser perdant perdre permettre perso personnage personnaliser personne personnellement personnification personnifier perspectif persécution pertinent perturber pesticide peucheure peuchère peur peut- peut-être philosophique photo phraser pic picsou pied pimousses piquer pister pitité pitié pizza placer plafond plaire plaisanter plaisanterie planter planète plastifier plastiquer plausible plumer plusieurs plutôt pochoir poindre poing point pointer poire poison polluer pollution pommer porridge porter poser position positionner possibilité possiblement poster posture poule poum pour pourquoi pourrir pourtant pousser pouvoir prendre preque presque principe printemps priori priviliégier privilégier pro problème producteur production produire produit programmer progresser promo promotion promouvoir promu proportion propos proposer protéger prouver proximité près précédemment préfèrerait préférer préparer présentable présenter préserver prévenir prévention prêter pub publicitaire publicité puce puisque punir pupille putain père périmer période qu quand quantité quart quasi quatre que quel quelqu'un quelque question queue qui quiquinette quiu quoi quoique r rabougrir raciste raconter radioactif radioactivité ragoutant ragoutante ragoûter raison raisonnement rajout rajouter ramener ramer rapelle rapidement rappeler rapport rapprocher rat ratatouille rater rauquer rayer rayure re-réfléchissant reafficher reagrd rebeller recette recevoir recommencer reconnait reconnaitraient reconnaitre reconnaître recueillement recycler redire redouter refaire refléter regard regarder registre rejection rejeter rejettée rejettés relativement relier remake remarcher remarquer remasterisés remasteré remettre remontrer remplir rendre rentrer renvoyer reparler repartir repasser repenser reprendre reprocher représenter respect ressembler ressortir rester retenir retirer retomber retour retourner retrouver revenir revenu revoir rien rigolo rigueur rimer ring risquer robot ronchon roser rouler router ruban ruer rugueux run rupture rustre réaction réaliste réalité récolter récupérable récupérer réflexe réflexion réfléchir référence régional régler réparents répertoire répondre réponse répulse répulsif répéter réserver réussir réveiller s. saboter sainement saison salade saler salle salut sandwich sans santé sardonique sauf sauter sauver savoir scrutateur scène sdf se secondaire seconder secouer sectionner self selon sembler sensation sensibilisation sensé sentiment sentir serrer session set seulement sexe signer significatif signification signifier simplifier sinon site situer six ski slogan smeble sobre société soda soi soigner sol solaire soleil sombrer son sortir sou souci souffrir sourcil sous-titrer souvenir souvent spectateur spectre spiderman spécialement spécialiste stade stone styler subir succès sucrer sucrerie sud suffire suffisamment suggestion suggérer suite suivre sujet super-héros superficiel superman supermarché supposer sur surface surprendre surproduction surréaliste sursélectionnés surtout surtraités surveiller survivre suspendre suspense symbole sympathie synonyme synthèse sécher séparation séparemment séparer série sévérité sûrement t tabasser tagada tailler taire tant taper tard technique tel temps tendance tenir terme terminer terrer terrifier teuf texte texture thierry thème thèse thématique tien tilter tirer tomate tombant tomber ton top topo tort tortu tortue toucher toujours tour tourner tournoi tracasser train trainer trait traitement traiter trajet trancher transformation transformer transgénérationnel transition transport transporter traumatiser travailler travers traverser triangle triangulaire tricher trier trimbaler tristesse tristounet trois tromper trompeux tropical tropico trou trouver truc tuer turban twister typer typiquement tâcher télé téléspectateur télévision tête un unir univers usage user utilisation utiliser vachement valeur vallu valoir valoriser valser varier vegans vendeur vendre venir vent venère ver version versus viande vibe victime vie vieillir vindicatif violence violenter violer visage viser vision visuel vitamine vite vivre voilà voir voire voix volume voter votre vouloir voyager voyageur vu végétarien véhiculer véner vénérer vérité wouah x yep yes youtube yu yé z zeste zezette zorro à àsuperman âge ça écarter échapper écho échouer éclair éclater école écoligiste écologie économie écorcer écorcher écouter écraser écrire écrit écriture éducation éduquer égaler égout égoût élaborer élever émotionnel énergie énergisant énergétique énerver énormément épauler éplucher épluchure éponger époux équilibrer équivalence étaler étape état éthique étirer étit étonner éventuellement évider éviter évoquer être ôcre"
    }
   ],
   "source": [
    "for d in rem_vocab:\n",
    "    print(d, end=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non polarised ADJ:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "\"abimé abîmer accrocher acheter agir ah aimble aimer alcoolique alimentaire aller allo amocher amuser amérique animer annoncer appetissante apple apprécier appétissant appêtissant appêtissante asiatique attendre attractif attrayant au auquel automatique autrichien aux auxquels avoir bagarrer bah ballant baraque barbu barrer batman beh ben bio biologique blaser bourrer brillanter briller bruire brut c'est-à-diree ca cabosser cagoule celui-là certes cheveu chimique cibler cifre citron clé cogner coller combattres comestible comment complexer compliquer compléter comprendre concilier connaître consensus contenter contraster cool courber croire croquant crédible deadpool dedans dessiner devoir difformer dire docker domestiquer donald du duck décaler découper décrire défendre déformer défraichie dégoulinant dégueuler déguisement dépressif désoler déterminer empathique endroit enfant engager ensemble entendre entrer envers esthétique euhh exceller excuser expliquer expressif exprimer faillir faire fait fanta farfelu fatiguer fente feuiller fiable flasque fondre formatées frai fraiser framboise frapper fruit fruitier genre globuleux gonfler graver groseille gueuler guillemet gélatineux habitude halloween hein hyper importer impressionner inaperçu indéchiffrable indéfinissable inhabituel intergénérationnel interner interroger intéresser inverser jack justicier juteux kart laitier lasser lequel lisser ludique lui lutter là-bas là-dessus légume malformée mangeable manger marrer marvel masser mesquin mettre mh millionaire mineur modéliser mojitos monsanto montrer morganer motiver mouais moulant mythique mécher n'- nickel ninja ninjas niquel nourriture nutritif négatif négative oasis obliger ok olive ouais paradoxal pardon parler paumer pause peler penser personnifier pertinent pesticide peuchère peut-être philosophique pitié plaire plastiquer plausible poire pommer possiblement pouvoir produit promu proposer présentable prêter pub publicitaire quel quoique r raciste radioactif ragoutante rajouter rapprocher rater rauquer rebeller regarder remarquer repartir ressembler roser rugueux rustre réaliste récupérable récupérer réflexe régional répulsif réussir sainement saler sardonique sauter savoir secondaire seconder sentir significatif smeble sobre soi sombrer sortir souci souvenir spiderman sucrer super-héros superman surprendre surréaliste sursélectionnés surveiller synonyme synthèse tagada tailler taire technique tel terrifier teuf thématique tombant ton tortue tracasser train traiter transgénérationnel triangle triangulaire trier trompeux tropical trouver truc tête univers venère victime vindicatif violenter viser visuel vivre voilà voir vouloir végétarien vénérer ça école écoligiste écorcher écraser égaler égout élever émotionnel énergisant énergétique énerver épauler éplucher époux étaler étonner éventuellement évider évoquer être\""
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "' '.join([x for x,a in used_vocab if (a == 'ADJ' and x not in sel_vocab.form.values)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some weird words in this list: \"là-bas\" \"là-dessus\" definitely aren't ADJ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Marsatag POS analysis & word comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "marsadir = os.path.join(CURRENTDIR, \"convers/marsatag/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_marsa(file_path):\n",
    "    tree = ElementTree.parse(file_path)\n",
    "    # getroot() gets document, getchildren()[0] gets sample ==> access tokens\n",
    "    return tree.getroot().getchildren()[0] \n",
    "\n",
    "def marsatag_to_pandas(document, with_inserted=True):\n",
    "    \"\"\"Select words & tags from xml \n",
    "    \n",
    "    Input:\n",
    "    -------\n",
    "    document: xml.etree.ElementTree.Element\n",
    "    with_inserted: bool\n",
    "        whether to remove punctuation inserted by MarsaTag\n",
    "    \n",
    "    Output:\n",
    "    -------\n",
    "    sentence: dataframe\n",
    "        shape ['form', 'pos', 'lemma', 'inserted']\n",
    "    \"\"\"\n",
    "    sentence = []\n",
    "    d = {'A': 'ADJ', 'D':'DET', 'R': 'ADV', 'V': 'VERB', 'C': 'CONJ', 'N': 'NOUN', \n",
    "         'S':'PREP', 'W':'PUNCT', 'I':'INTJ', 'P':'PRON', 'U':'X'}\n",
    "    for child in document:\n",
    "        if child.tag == 'token':\n",
    "            # first child is solution, if exists\n",
    "            try:\n",
    "                sentence.append({'form': child.attrib['form'], \\\n",
    "                             'pos': d[child.attrib['features'][0]], \\\n",
    "                             'lemma': None if 'lemma' not in child.attrib.keys() else child.attrib['lemma'], \\\n",
    "                             'inserted': (child.attrib['regex_type'] == 'inserted') \\\n",
    "                            })\n",
    "            except: # erreur de type \"\"\"<token form=\"-\" regex_type=\"Ponct_Wm1\">\"\"\"\n",
    "                sentence.append({'form': child.attrib['form'], \\\n",
    "                             'pos': 'PUNCT', \\\n",
    "                             'lemma': None if 'lemma' not in child.attrib.keys() else child.attrib['lemma'], \\\n",
    "                             'inserted': (child.attrib['regex_type'] == 'inserted') \\\n",
    "                            })\n",
    "    if with_inserted:\n",
    "        return pd.DataFrame(sentence)\n",
    "    else:\n",
    "        p = pd.DataFrame(sentence)\n",
    "        return p[~p.inserted]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading POS from MarsaTag requires loading data from XML:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(82364, 4)"
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "marsa_pd = []\n",
    "for f in sorted(os.listdir(marsadir)):\n",
    "    if '.xml' in f:\n",
    "        marsa_pd.append(marsatag_to_pandas(read_marsa(os.path.join(marsadir, f)), with_inserted=False))\n",
    "marsa_pd = pd.concat(marsa_pd)\n",
    "marsa_pd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "    form   pos  lemma  inserted\n0     ah  INTJ     ah     False\n2  ouais  INTJ  ouais     False\n4     c'  PRON     ce     False\n5    est  VERB   être     False\n7     un   DET     un     False",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>form</th>\n      <th>pos</th>\n      <th>lemma</th>\n      <th>inserted</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ah</td>\n      <td>INTJ</td>\n      <td>ah</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ouais</td>\n      <td>INTJ</td>\n      <td>ouais</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>c'</td>\n      <td>PRON</td>\n      <td>ce</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>est</td>\n      <td>VERB</td>\n      <td>être</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>un</td>\n      <td>DET</td>\n      <td>un</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "marsa_pd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using same format as earlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([('ah', 'INTJ'), ('ouais', 'INTJ'), ('ce', 'PRON'), ...,\n       ('parce_que', 'CONJ'), ('ce', 'PRON'), ('être', 'VERB')],\n      dtype=object)"
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "marsa_pd.apply(lambda x: (x.lemma, x.pos), axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(314, 5)"
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "u_marsa = [x for x,_ in list(marsa_pd.apply(lambda x: (x.lemma, x.pos), axis=1).values) if x is not None]\n",
    "sel_marsa = pd_vocab[pd_vocab.form.isin(u_marsa)]\n",
    "sel_marsa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "1556"
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "rem_marsa = sorted(list(set(u_marsa) - set(pd_vocab[pd_vocab.form.isin(u_marsa)].form.values)))\n",
    "len(rem_marsa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'abandonner abîmer acide affaiblir affaisser aimer alcoolique alimentaire allonger allô ambivalent amoché amuser animer antioxydant appétissant arrondir aseptisé attaquer attractif attrayant automatique autrichien ballant barbu battre bio biologique blaser brunir brut cabossé calibrer casser chimique cinq clean clore cohérent colorer comestible comparer conciliant connaître conservateur considérer contrarier cool croquant crédible cuire dessiner deux disperser disproportionné donner déborder décaler décorer découper défendre défoncer déformer défraîchir dégrader déguiser démoraliser dépité dépressif déprimer dériver désespérer déterminer développer expert expressif fait farfelu fatiguer fiable flasque fondre frapper frit fruitier funky globuleux gélatineux habiller handicapé inaperçu indéchiffrable indéfinissable inhabituel intentionné interdire intuitif issu jeter justifier juteux laitier lassé lever live ludique lustré mangeable marquant masquer mesquin moisir moulant mythique nutritif négatif négliger obliger offensif oublier paradoxal parlant perdre perso personnifier pertinent pesticide philosophique plastifié plausible pourrir producteur protéger préférer présentable publicitaire périmer quatre raciste radioactif ragoûtant rapprocher rebelle remplir rigolo ronchon rugueux ré réaliste récupérable régional répulsif réussir sardonique scrutateur secondaire sensé significatif sobre solaire sucrer suivre superficiel sur surréaliste suspendre sécher tailler taper technique tel tenir tombant tortu triangulaire tristounet trois tropical typique usé vieillir vindicatif visuel voir végétarien écraser émotionnel énergisant énergétique énerver équilibrer étaler'"
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "' '.join(sorted(list(set([x for x,a in list(marsa_pd.apply(lambda x: (x.lemma, x.pos), axis=1).values) if (a == 'ADJ' and x not in sel_marsa.form.values and x is not None)]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "             form polarity subjectivity intensity confidence\n21      abordable     0.15         0.30       1.0        0.7\n38     absolument     0.25         0.75       2.0        0.9\n60     acceptable     0.05         0.10       1.0        0.7\n174       affreux    -0.80         0.80       1.0        0.9\n190      agressif    -0.80         0.80       1.0        0.9\n211       aimable     0.90         0.80       1.0        0.9\n239      allemand     0.00         0.00       1.0        1.0\n262     aléatoire    -0.05        -0.10       1.0        0.7\n272        ambigu    -0.05         1.00       1.0        0.9\n291       amusant     0.40         0.75       1.0        0.9\n301     américain     0.08         0.10       1.0        1.0\n331    angoissant    -0.27        -0.50       1.0        0.7\n339     angélique     0.05         0.10       1.0        0.7\n425        arrivé     0.10         0.10       1.0        0.9\n429       arrière     0.00         0.00       1.0        0.9\n442    artificiel    -0.10         0.00       1.0        0.9\n446    artistique     0.10         0.20       1.0        0.9\n482     attachant     0.23         0.30       1.0        0.7\n500      attirant     0.31         0.70       1.0        0.7\n513     aubergine     0.00         0.00       1.0        0.7\n521       austère    -0.10         0.55       1.0        0.9\n533         autre    -0.10         0.00       1.0        1.0\n568     bagarreur    -0.10        -0.20       1.0        0.7\n588           bas    -0.20         0.00       1.0        1.0\n599       battant    -0.20         0.25       1.0        0.9\n607        bavard    -0.30         0.65       1.0        0.9\n611          beau     0.80         0.80       1.0        1.0\n613      beaucoup     0.10         0.10       1.2        0.8\n629          bien     0.00         0.20       1.0        0.9\n641  bienveillant     0.38         0.80       1.0        0.7\n651       bizarre    -0.40         0.40       1.0        1.0\n657         blanc     0.05         0.00       1.0        1.0\n669          bleu     0.04         0.00       1.0        1.0\n688           bon     0.70         0.70       1.0        1.0\n690      bonhomme     0.35         0.70       1.0        0.7\n727          bref     0.08         0.20       1.0        1.0\n733      brillant     0.65         0.70       1.0        1.0\n743          brun     0.00         0.00       1.0        1.0\n781          bête    -0.50         0.50       1.0        0.9\n811   capitaliste    -0.05        -0.10       1.0        0.7",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>form</th>\n      <th>polarity</th>\n      <th>subjectivity</th>\n      <th>intensity</th>\n      <th>confidence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>21</th>\n      <td>abordable</td>\n      <td>0.15</td>\n      <td>0.30</td>\n      <td>1.0</td>\n      <td>0.7</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>absolument</td>\n      <td>0.25</td>\n      <td>0.75</td>\n      <td>2.0</td>\n      <td>0.9</td>\n    </tr>\n    <tr>\n      <th>60</th>\n      <td>acceptable</td>\n      <td>0.05</td>\n      <td>0.10</td>\n      <td>1.0</td>\n      <td>0.7</td>\n    </tr>\n    <tr>\n      <th>174</th>\n      <td>affreux</td>\n      <td>-0.80</td>\n      <td>0.80</td>\n      <td>1.0</td>\n      <td>0.9</td>\n    </tr>\n    <tr>\n      <th>190</th>\n      <td>agressif</td>\n      <td>-0.80</td>\n      <td>0.80</td>\n      <td>1.0</td>\n      <td>0.9</td>\n    </tr>\n    <tr>\n      <th>211</th>\n      <td>aimable</td>\n      <td>0.90</td>\n      <td>0.80</td>\n      <td>1.0</td>\n      <td>0.9</td>\n    </tr>\n    <tr>\n      <th>239</th>\n      <td>allemand</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>262</th>\n      <td>aléatoire</td>\n      <td>-0.05</td>\n      <td>-0.10</td>\n      <td>1.0</td>\n      <td>0.7</td>\n    </tr>\n    <tr>\n      <th>272</th>\n      <td>ambigu</td>\n      <td>-0.05</td>\n      <td>1.00</td>\n      <td>1.0</td>\n      <td>0.9</td>\n    </tr>\n    <tr>\n      <th>291</th>\n      <td>amusant</td>\n      <td>0.40</td>\n      <td>0.75</td>\n      <td>1.0</td>\n      <td>0.9</td>\n    </tr>\n    <tr>\n      <th>301</th>\n      <td>américain</td>\n      <td>0.08</td>\n      <td>0.10</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>331</th>\n      <td>angoissant</td>\n      <td>-0.27</td>\n      <td>-0.50</td>\n      <td>1.0</td>\n      <td>0.7</td>\n    </tr>\n    <tr>\n      <th>339</th>\n      <td>angélique</td>\n      <td>0.05</td>\n      <td>0.10</td>\n      <td>1.0</td>\n      <td>0.7</td>\n    </tr>\n    <tr>\n      <th>425</th>\n      <td>arrivé</td>\n      <td>0.10</td>\n      <td>0.10</td>\n      <td>1.0</td>\n      <td>0.9</td>\n    </tr>\n    <tr>\n      <th>429</th>\n      <td>arrière</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>1.0</td>\n      <td>0.9</td>\n    </tr>\n    <tr>\n      <th>442</th>\n      <td>artificiel</td>\n      <td>-0.10</td>\n      <td>0.00</td>\n      <td>1.0</td>\n      <td>0.9</td>\n    </tr>\n    <tr>\n      <th>446</th>\n      <td>artistique</td>\n      <td>0.10</td>\n      <td>0.20</td>\n      <td>1.0</td>\n      <td>0.9</td>\n    </tr>\n    <tr>\n      <th>482</th>\n      <td>attachant</td>\n      <td>0.23</td>\n      <td>0.30</td>\n      <td>1.0</td>\n      <td>0.7</td>\n    </tr>\n    <tr>\n      <th>500</th>\n      <td>attirant</td>\n      <td>0.31</td>\n      <td>0.70</td>\n      <td>1.0</td>\n      <td>0.7</td>\n    </tr>\n    <tr>\n      <th>513</th>\n      <td>aubergine</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>1.0</td>\n      <td>0.7</td>\n    </tr>\n    <tr>\n      <th>521</th>\n      <td>austère</td>\n      <td>-0.10</td>\n      <td>0.55</td>\n      <td>1.0</td>\n      <td>0.9</td>\n    </tr>\n    <tr>\n      <th>533</th>\n      <td>autre</td>\n      <td>-0.10</td>\n      <td>0.00</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>568</th>\n      <td>bagarreur</td>\n      <td>-0.10</td>\n      <td>-0.20</td>\n      <td>1.0</td>\n      <td>0.7</td>\n    </tr>\n    <tr>\n      <th>588</th>\n      <td>bas</td>\n      <td>-0.20</td>\n      <td>0.00</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>599</th>\n      <td>battant</td>\n      <td>-0.20</td>\n      <td>0.25</td>\n      <td>1.0</td>\n      <td>0.9</td>\n    </tr>\n    <tr>\n      <th>607</th>\n      <td>bavard</td>\n      <td>-0.30</td>\n      <td>0.65</td>\n      <td>1.0</td>\n      <td>0.9</td>\n    </tr>\n    <tr>\n      <th>611</th>\n      <td>beau</td>\n      <td>0.80</td>\n      <td>0.80</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>613</th>\n      <td>beaucoup</td>\n      <td>0.10</td>\n      <td>0.10</td>\n      <td>1.2</td>\n      <td>0.8</td>\n    </tr>\n    <tr>\n      <th>629</th>\n      <td>bien</td>\n      <td>0.00</td>\n      <td>0.20</td>\n      <td>1.0</td>\n      <td>0.9</td>\n    </tr>\n    <tr>\n      <th>641</th>\n      <td>bienveillant</td>\n      <td>0.38</td>\n      <td>0.80</td>\n      <td>1.0</td>\n      <td>0.7</td>\n    </tr>\n    <tr>\n      <th>651</th>\n      <td>bizarre</td>\n      <td>-0.40</td>\n      <td>0.40</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>657</th>\n      <td>blanc</td>\n      <td>0.05</td>\n      <td>0.00</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>669</th>\n      <td>bleu</td>\n      <td>0.04</td>\n      <td>0.00</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>688</th>\n      <td>bon</td>\n      <td>0.70</td>\n      <td>0.70</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>690</th>\n      <td>bonhomme</td>\n      <td>0.35</td>\n      <td>0.70</td>\n      <td>1.0</td>\n      <td>0.7</td>\n    </tr>\n    <tr>\n      <th>727</th>\n      <td>bref</td>\n      <td>0.08</td>\n      <td>0.20</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>733</th>\n      <td>brillant</td>\n      <td>0.65</td>\n      <td>0.70</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>743</th>\n      <td>brun</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>781</th>\n      <td>bête</td>\n      <td>-0.50</td>\n      <td>0.50</td>\n      <td>1.0</td>\n      <td>0.9</td>\n    </tr>\n    <tr>\n      <th>811</th>\n      <td>capitaliste</td>\n      <td>-0.05</td>\n      <td>-0.10</td>\n      <td>1.0</td>\n      <td>0.7</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "sel_marsa.head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter('marsa_compare.xlsx') as writer:  \n",
    "    for f in ['ADJ', 'PREP', 'ADV', 'VERB', 'CONJ', 'DET', 'INTJ', 'NOUN', 'PRON']:\n",
    "        marsa_pd[marsa_pd.pos == f][['form', 'pos', 'lemma']].drop_duplicates().sort_values(by='form').to_excel(writer, sheet_name=f, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37364bitanaconda3virtualenvf4ae0adae11f4651a06ea79eb5fcd3ff",
   "display_name": "Python 3.7.3 64-bit ('anaconda3': virtualenv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}